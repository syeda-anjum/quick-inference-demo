load:
  type: constant
  stages:
  - rate: 1
    duration: 30
api: 
  type: completion
  streaming: true
server:
  type: vllm
  model_name: Qwen/Qwen2.5-32B-Instruct
  base_url: http://vllm-service.default.svc.cluster.local:8000
  ignore_eos: true
tokenizer:
  pretrained_model_name_or_path: Qwen/Qwen2.5-32B-Instruct
data:
  type: random
  input_distribution:
      min: 10             # min length of the synthetic prompts
      max: 100            # max length of the synthetic prompts
      mean: 50            # mean length of the synthetic prompts
      std: 10             # standard deviation of the length of the synthetic prompts
  output_distribution:
      min: 10             # min length of the output to be generated
      max: 100            # max length of the output to be generated
      mean: 50            # mean length of the output to be generated
      std: 10             # standard deviation of the length of the output to be generated
metrics:
  type: prometheus
  prometheus:
      scrape_interval: 15
      google_managed: true         # Whether using Google Managed Prometheus
      filters: [] 
report:
  request_lifecycle:
    summary: true
    per_stage: true
    per_request: false
  prometheus:
    summary: true
    per_stage: false
#storage:
#  google_cloud_storage:
#    bucket_name: gs://inf-perf-results
storage:
  google_cloud_storage:               # Optional GCS configuration
    bucket_name: "infperf-results"   # Required GCS bucket
    report_file_prefix: null          # Optional filename prefix



